## For BRC Prashant email ##

Log in: ssh psharma@brc3.secure.biotech.wisc.edu 
Password: +texErax3Ve@

Important when outside UW campus: you need to VPN in or be on the UWNet Wifi, or it won't let you log in.
to connect to UW VPN servive go to /opt/paloaltonetworks/globalprotect and execute the globalprotect aplication

globalprotect connect --portal uwmadison.vpn.wisc.edu

type username and password

ssh psharma@brchome.biotech.wisc.edu
sftp psharma@brchome.biotech.wisc.edu
Password: +texErax3Ve@

To copy from local to remote:
scp [your local file] psharma@brchome.biotech.wisc.edu:/home/BIOTECH/psharma/Luciano/[your remote folder]

To copy from remote to local:
scp psharma@brc3.secure.biotech.wisc.edu:/home/BIOTECH/psharma/Luciano/[your remote file] [your local folder]  

## TMUX ##

To make a new tmux session called "MySession": 
tmux new -s MySession

To disconnect from the tmux session so you can close your computer, type "control+b" and then "d"

To attach to the tmux session to check on your run, type:
tmux a -t MySession

BEAST on BRC about 3h/millionGen [runs a lot faster on Cipres, only 24min/millonGen]

## Beast version 2.5.1 ##
at:
/home/BIOTECH/psharma/local/beast/bin

create a beauti file on your computer and try to run with beast from BRC

to run beast from terminal
(extracted from Beast homepage)

/home/BIOTECH/psharma/local/beast/bin/beast -working -prefix AssamBEASTuni  beast.xml

BEAST arguments:

-window         "Provide a console window"

-options        "Display an options dialog"

     -working        "Change working directory to input file's directory"

-seed           "Specify a random number generator seed"

     -prefix         "Specify a prefix for all output log filenames"

-overwrite      "Allow overwriting of log files"

-errors         "Specify maximum number of numerical errors before stopping"

-threads        "The number of computational threads to use (default auto)"

-java           "Use Java only, no native implementations"

-beagle         "Use beagle library if available"

-beagle_info          "BEAGLE: show information on available resources"

-beagle_order         "BEAGLE: set order of resource use"

-beagle_instances     "BEAGLE: divide site patterns amongst instances"

-beagle_CPU           "BEAGLE: use CPU instance"

-beagle_GPU           "BEAGLE: use GPU instance if available"

-beagle_SSE           "BEAGLE: use SSE extensions if available"

-beagle_single        "BEAGLE: use single precision if available"

-beagle_double        "BEAGLE: use double precision if available"

-beagle_scaling       "BEAGLE: specify scaling scheme to use"

-help"                "Print this information and stop"

Assuming BEAST is installed in your home directory (as ~/beast), you can call BEAST programs from a terminal using

~/beast/bin/beast -threads 4 beast.xml

to start BEAST on beast.xml with 4 threads. If you have BEAST installed in a different location, you need to replace ~/beast with the location where beast can be found. All programs (applauncher, beast, beauti, densitree, loganalyser, logcombiner, packagemanager, and treeannotator) are in the bin folder, and can be started likewise, for example

~/beast/bin/applauncher BModelAnalyser -file beast.log

to run BModelAnalyser on file beast.log, or

~/beast/bin/packagemanager -add bModelTest

to install the bModelTest package.
Increasing memory after a java.lang.OutOfMemoryError on Linux

To increase memory available to BEAST or any of the other program you can use the -Xmx directive for java. For example, to allocate 16GB of memory for BEAST, use

java -Xmx16g -jar ~/beast/lib/launcher.jar -threads 4 beast.xml

You can also edit the scripts in the bin directory and call the script instead. Note, there will be two places to update.

## Phylobayes 4.1c ##
at:
/home/BIOTECH/psharma/local/phylobayes4.1c/data

usage

pb -f -d Opiliones005.phy -T Assamiidae005_besttree.newick -x 10 -dgam 4 -gtr -cat -covarion -gbl Assam005partitions assam005pb

/home/BIOTECH/psharma/local/phylobayes4.1c/data/pb -f -d Opiliones005.phy -T Assamiidae005_besttree.newick -gtr -cat -covarion -gbl Assam005partitions assam005pb
## Qiime 2 microbiome search ##

# before you start (some shenanigans)
The first spet for a analisys with qiime is make sure you have conda installed.
then create a new environment. Pay attention on the phyton version to install the right miniconda version.

conda create --name [environment name]

then you have to activate it defore star working on qiime

conda activate [environment name]

after that qiime should work just fine (nada, o cu do biotech nao funciona! Colocar o caminho inteiro para o comando 
* "/home/BIOTECH/psharma/miniconda3/envs/qiime2-2021.4/bin/qiime" 

To start the analysis make sure all the files and folders are in place. 
If you are outside UW campus you;ll need to connect to the VPN system before accessing the BRC cluster, refer to line one of this script to more information on how to connect.

# importing files (the quest!)

For the type of data we receive from the biotech-center the most practice way to import the data to qiime is when it is already demultiplexed with cutadapt.
There is bug on the qiime's cutadapt script that make the header of the first column as the sequence name. This caused a not a IUPAC character **(name of the colunm)** being read as the the first barcode which precludes subsequent analysis.

To contour this problem the vbest way (after several hours of work!) is to use cutadapt first, outside qiime.

run any of the following:

cutadapt -e 0.15 --no-indels --cores=0 --discard-untrimmed -g file:barcode_file.fasta -o "qquer-nome.fastq.gz" input_file.fastq.gz
cutadapt -e 0.15 --no-indels --cores=0 --discard-untrimmed -g file:barcode_file.fasta -o "forward{name}_L002_R1_001.fastq.gz" input_file.fastq.gz
cutadapt -e 0.15 --no-indels --cores=0 --discard-untrimmed -g file:barcode_file.fasta -o "reverse{name}_L002_R2_001.fastq.gz" input_file.fastq.gz

cutadapt will sort out your samples and give them a name you used in the command above.
You should then pul all the demultiplexd samples in the same folder and rename them accordingly.
The names need to have five "fields" separated by underscores, this format is called Casava 1.8.
The file name includes the sample identifier and should look like **L2S357_15_L001_R1_001.fastq.gz.** 
The underscore-separated fields in this file name are:

the sample identifier,
the barcode sequence or a barcode identifier,
the lane number,
the direction of the read (R1 for forward, or R2 for reverse reads), and
the set number.

After the samples are renamed the data can finally be imported into qiime

run:

* paired-end

/home/BIOTECH/psharma/miniconda3/envs/qiime2-2021.4/bin/qiime tools import --type 'SampleData[PairedEndSequencesWithQuality]' --input-path ./demultiplexed --input-format CasavaOneEightSingleLanePerSampleDirFmt --output-path brazil-demux.qza

* single end
qiime tools import --type 'SampleData[SequencesWithQuality]' --input-path ./demultiplexed-forward --input-format CasavaOneEightSingleLanePerSampleDirFmt --output-path demux-single.qza


* Casava 1.8 single-end demultiplexed fastq (original command)

Importing data
qiime tools import \
  --type 'SampleData[SequencesWithQuality]' \
  --input-path casava-18-single-end-demultiplexed \
  --input-format CasavaOneEightSingleLanePerSampleDirFmt \
  --output-path demux-single-end.qza

* Casava 1.8 paired-end demultiplexed fastq (original command)

Importing data
qiime tools import \
  --type 'SampleData[PairedEndSequencesWithQuality]' \
  --input-path casava-18-paired-end-demultiplexed \
  --input-format CasavaOneEightSingleLanePerSampleDirFmt \
  --output-path demux-paired-end.qza

* summarizing the demultiplexing output

run:

/home/BIOTECH/psharma/miniconda3/envs/qiime2-2021.4/bin/qiime demux summarize --i-data brazil-demux.qza --o-visualization brazil-demux.qzv
/home/BIOTECH/psharma/miniconda3/envs/qiime2-2021.4/bin/qiime tools export --input-path brazil-demux.qzv --output-path ./demux-summary/

qiime demux summarize --i-data demux-single.qza --o-visualization demux-single.qzv
qiime tools export --input-path demux-single.qzv --output-path ./demux-single-summary/

* metada file obs
Barcodes in the metadata mapping file are not required to be in any specific order.
To avoid running erros it is good to validate the metadata file on google sheets using KEEMEI aad-on.
If you use Keemei for any published research, include the following citation:
* Keemei: cloud-based validation of tabular bioinformatics file formats in Google Sheets. Rideout JR, Chase JH, Bolyen E, Ackermann G, GonzÃ¡lez A, Knight R, Caporaso JG. GigaScience. 2016;5:27. http://dx.doi.org/10.1186/s13742-016-0133-6*

* if the files are to big we can subsample to take a look without processing all the reads (this is just for curiosity purposes)

qiime demux subsample-paired --i-sequences gut-demux.qza --p-fraction 0.1 --o-subsampled-sequences gut-demux-subsample.qza

qiime demux summarize --i-data gut-demux-subsample.qza --o-visualization gut-demux-subsample.qzv



# Denoising

Before setting the numbers for the denoising analysis below check the summary of QC on the demultiplexed samples, the summary will help you to decide when and how much to trim. Trimming is not mandatory.

* paired end

/home/BIOTECH/psharma/miniconda3/envs/qiime2-2021.4/bin/

* qiime demux filter-samples --i-demux demux.qza --m-metadata-file ./demux-summary/per-sample-fastq-counts.tsv --p-where 'CAST([forward sequence count] AS INT) > 100' --o-filtered-demux demux-filtered.qza

* qiime dada2 denoise-paired --i-demultiplexed-seqs demux.qza --p-trim-left-f 5 --p-trim-left-r 5 --p-trunc-len-f 130 --p-trunc-len-r 130 --o-table table.qza --o-representative-sequences rep-seqs.qza --o-denoising-stats denoising-stats.qza

* single end (this step takes several hours to run, e.g. more than 24 hours for eight Metamasius samples)

qiime dada2 denoise-single --i-demultiplexed-seqs demux-single.qza --p-trim-left 0 --p-trunc-len 120 --o-representative-sequences repseqs-dada2_single.qza --o-table table-dada2-single.qza --o-denoising-stats stats-dada2-single.qza

qiime metadata tabulate --m-input-file stats-dada2-single.qza --o-visualization stats-dada2-single.qzv

# Clustering features

* De novo clustering

qiime vsearch cluster-features-de-novo --i-table table-dada2-single.qza --i-sequences repseqs-dada2_single.qza --p-perc-identity 0.99 --o-clustered-table table-dada2-single-clustered.qza --o-clustered-sequences rep-seqs-dada2-single-clustered.qza

# Chimera filtering

* run de novo chimera checking

qiime vsearch uchime-denovo --i-table table-dada2-single-clustered.qza --i-sequences rep-seqs-dada2-single-clustered.qza --output-dir unchimera-single-out

qiime metadata tabulate --m-input-file unchimera-single-out/stats.qza --o-visualization unchimera-single-out/stats.qzv

qiime tools export --input-path unchimera-single-out/stats.qzv --output-path unchimera-single-out/unchimera-stats-summary/

* Excluding chimeras and "bordeline chimeras"

qiime feature-table filter-features --i-table table-dada2-single-clustered.qza --m-metadata-file unchimera-single-out/nonchimeras.qza --o-filtered-table unchimera-single-out/table-nonchimeric.qza

qiime feature-table filter-seqs --i-data rep-seqs-dada2-single-clustered.qza --m-metadata-file unchimera-single-out/nonchimeras.qza --o-filtered-data unchimera-single-out/rep-seqs-nonchimeric.qza

* summarazing and exporting

qiime feature-table summarize --i-table unchimera-single-out/table-nonchimeric.qza --o-visualization unchimera-single-out/table-nonchimeric.qzv
qiime tools export --input-path unchimera-single-out/table-nonchimeric.qzv --output-path unchimera-single-out/nonchimeric-summary/

# Training feature classifiers with q2-feature-classifier

qiime tools import --type 'FeatureData[Sequence]' --input-path genome.fasta --output-path nardonella_genome.qza

qiime tools import --type 'FeatureData[Taxonomy]' --input-format HeaderlessTSVTaxonomyFormat --input-path nardonella_taxonomy.txt --output-path nardonella-taxonomy.qza

qiime feature-classifier fit-classifier-naive-bayes --i-reference-reads nardonella_genome.qza --i-reference-taxonomy nardonella-taxonomy.qza --o-classifier nardo-classifier.qza

qiime feature-classifier classify-sklearn --i-classifier nardo-classifier.qza --i-reads rep-seqs-nonchimeric.qza --o-classification rep-seqs-taxonomy.qza

qiime metadata tabulate --m-input-file rep-seqs-taxonomy.qza --o-visualization rep-seqs-taxonomy.qzv

qiime tools export --input-path rep-seqs-taxonomy.qzv --output-path ./taxonomy-summary/

# barplot for data visualization

qiime taxa barplot --i-table table-nonchimeric.qza --i-taxonomy rep-seqs-taxonomy.qza --m-metadata-file RADmetamasius_metadata.tsv --o-visualization taxa-bar-plots.qzv

qiime tools export --input-path taxa-bar-plots.qzv --output-path ./barplots-summary/

# Phylogenies
# Aligning the sequences

qiime phylogeny align-to-tree-mafft-fasttree --i-sequences rep-seqs-nonchimeric.qza --p-n-threads 'auto' --p-parttree --o-alignment aligned-rep-seqs.qza --o-masked-alignment masked-aligned-rep-seqs.qza  --o-tree unrooted-tree.qza --o-rooted-tree rooted-tree.qza


